{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNZ3YbBOPHQh"
      },
      "source": [
        "## Rubric\n",
        "\n",
        "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report.\n",
        "\n",
        "Scoring: Out of 10 points\n",
        "\n",
        "- Each Developing  => -2 pts\n",
        "- Each Unsatisfactory/Missing => -4 pts\n",
        "  - until the score is\n",
        "\n",
        "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
        "\n",
        "\n",
        "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
        "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
        "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
        "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frK1JUgcPHQi"
      },
      "source": [
        "# COGS 108 - Data Checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43qr66GXPHQi"
      },
      "source": [
        "## Authors\n",
        "\n",
        "\n",
        "Team list and credits:\n",
        "- Katelyn Yap: Conceptualization, Data set 1, Writing - code cleanup\n",
        "- Vy Nguyen: Ethics Revision, Project Timeline Proposal, Dataset 3\n",
        "- Charlie Chang: Project administration, Software, Writing - review & editing\n",
        "- Dani Delgado: Analysis, Background research, Visualization, Writing - original draft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do2DOZFoPHQi"
      },
      "source": [
        "## Research Question\n",
        "\n",
        "To what extent does variation in daily Air Quality Index (AQI), as measured by the U.S. Environmental Protection Agency (EPA), explain variation in daily visitor trailhead sensor counts in Yosemite National Park between 1990 and 2024, controlling for daily maximum temperature and total precipitation?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZooD5CwPHQi"
      },
      "source": [
        "## Background and Prior Work\n",
        "\n",
        "Outdoor recreation in national parks is influenced by environmental conditions that affect both visitor safety and overall experience. In the western United States, air quality has become an increasingly important factor due to wildfire smoke and regional pollution. The U.S. Environmental Protection Agency’s Air Quality Index (AQI) is a standardized measure used to communicate the health risks associated with air pollution and to inform the public about outdoor activity safety.\n",
        "\n",
        "Because many national park activities involve extended outdoor physical activity, changes in air quality may affect visitors’ decisions about whether and when to visit. Understanding how air quality relates to park visitation is therefore relevant for park management, public health communication, and planning in highly visited parks such as Yosemite National Park.\n",
        "\n",
        "Previous research has established a clear connection between environmental conditions and tourism behavior. Buckley (2011) reviews existing literature on tourism and the environment and finds that weather, climate variability, and environmental quality consistently influence visitation patterns in natural areas. <a href=\"#ref1\">1</a> The review also notes that visitor responses differ depending on the type of destination and visitor motivations, suggesting that environmental effects may not be uniform across parks. However, Buckley’s work is conceptual and broad in scope, leaving open questions about how specific environmental indicators, such as AQI, influence visitation at individual parks.\n",
        "\n",
        "Empirical studies provide further evidence that air pollution affects park visitation. Keiser, Lade, and Rudik (2018) examine monthly visitation data from 33 U.S. national parks and find that higher ozone pollution levels are associated with reduced visitation, even after accounting for weather, seasonality, and park-specific differences. <a href=\"#ref2\">2</a> While this study demonstrates that air pollution can influence park use at a national scale, it relies on monthly averages and does not isolate park-specific daily behavioral responses. In addition, although Yosemite is included in their broader sample, the study does not focus specifically on Yosemite’s unique visitation patterns or wildfire-related air quality variability.\n",
        "\n",
        "More recent work has used alternative data sources to study visitation patterns at finer time scales. Minehart et al. (2025) analyze weekly visitation to parks and protected areas in the Pacific Northwest using anonymized mobile device data, examining the effects of temperature, precipitation, AQI, and particulate matter (PM2.5). <a href=\"#ref3\">3</a> The authors find that higher levels of PM2.5 are generally associated with lower visitation, while the relationship between AQI and visitation varies across different types of parks. However, their analysis aggregates across multiple parks and regions, making it difficult to determine how daily air quality fluctuations affect a single, high-profile destination over a long time horizon.\n",
        "\n",
        "Together, these studies suggest that environmental quality and weather conditions play an important role in shaping park visitation, while also highlighting important gaps in the literature. Much of the prior work relies on monthly or weekly data and emphasizes cross-park comparisons rather than park-specific, daily analysis. Furthermore, limited attention has been given to how short-term variation in AQI influences visitation in an iconic and highly visited park such as Yosemite, particularly over multiple decades that include periods of increasing wildfire activity.\n",
        "\n",
        "The present project addresses these gaps by examining whether daily variation in AQI predicts daily visitation to Yosemite National Park from 1979 to 2023, while controlling for daily maximum temperature and total precipitation. By focusing on a single park and using daily data, this study aims to capture short-term behavioral responses to air quality conditions that may be obscured in broader, aggregated analyses. This park-specific approach provides clearer insight into how air pollution influences visitation decisions in one of the most prominent national parks in the United States.\n",
        "\n",
        "1. <a name=\"ref1\"></a> Buckley, R. (2011). Tourism and environment. Annual Review of Environment and Resources, 36, 397–416. https://www.annualreviews.org/content/journals/10.1146/annurev-environ-041210-132637\n",
        "\n",
        "2. <a name=\"ref2\"></a> Keiser, D., Lade, G. E., & Rudik, I. (2018). Air pollution and visitation at U.S. national parks. Science Advances, 4(7). https://pmc.ncbi.nlm.nih.gov/articles/PMC6051738/\n",
        "\n",
        "3. <a name=\"ref3\"></a> Minehart, J., et al. (2025). The mountains are calling, but will visitors go? Modeling the effect of weather and air quality on visitation to Pacific Northwest parks and protected areas using mobile device data. https://www.researchgate.net/publication/390630027_The_mountains_are_calling_but_will_visitors_go_Modeling_the_effect_of_weather_and_air_quality_on_visitation_to_Pacific_Northwest_parks_and_protected_areas_using_mobile_device_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nOlo_rUPHQi"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNLYmXoZPHQj"
      },
      "source": [
        "## Hypothesis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA5OOv7EPHQj"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPpoQlqfPHQj"
      },
      "source": [
        "**bold text**## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w3jDSL_PHQj"
      },
      "source": [
        "### Data overview\n",
        "\n",
        "- Dataset #1: EPA Daily Air Quality Index in Mariposa County, CA\n",
        "  - Dataset Name: EPA Daily Air Quality Index - Mariposa County, CA\n",
        "  - Link to the dataset:https://www.epa.gov/outdoor-air-quality-data/download-daily-data\n",
        "  - Number of observations: Varies by year; ~one row per monitoring day per monitor. Over 44 years (1979–2023) this could be up to tens of thousands of rows depending on monitor availability and whether we need to aggregate to one AQI value per day.\n",
        "  - Number of variables: Typically 8–12 columns in the raw download, including: Date, Site Name, AQI, Category, the Defining Parameter, County, and State.\n",
        "  - Description of the variables most relevant to this project: Date, AQI, Defining Parameter(THIS MIGHT MEAN THE POLLUTANT THAT DRIVES THE AQI VALUE), and Category\n",
        "  - Descriptions of any shortcomings this dataset has with repsect to the project: Monitor availability pre-1990: The bulk daily AQI files go back only to 1990. Epa Monitoring data for Mariposa County before the early 1990s may be sparse or absent, which could significantly limit the usable date range of our 1979–2023 window. We may need to verify monitor start dates for the specific Yosemite Village / Mariposa County station before assuming full coverage.\n",
        "  - More shortcomings:\n",
        "     - Spatial mismatch: The nearest EPA monitor is at Yosemite Village, but AQI readings reflect one point in the park. Smoke and ozone conditions can vary substantially within the park's large geographic footprint, meaning the AQI value on any given day may not reflect conditions at every trailhead.\n",
        "     - Missing days: Monitors go offline for maintenance or equipment failure, producing gaps. Days with no reading are not the same as days with \"Good\" air quality, so missingness is not random and must be handled carefully.\n",
        "     - One AQI per day per county: If we use the county-level daily AQI summary file rather than the site-level file, we get a single AQI value per county per day (the maximum across all monitors), which smooths over intra-county variation.\n",
        "\n",
        "- Dataset #3: Daily Historical Weather Data - Yosemite National Park\n",
        "  - Dataset Name: NOAA Global\n",
        "  - Link to the dataset: Historical Climatology Network (GHCN) Daily – Yosemite Village Station (GHCND:USC00049855) https://www.ncei.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USC00049855/detail\n",
        "  - Number of observations: Approximately 12,418 rows. This represents one observation for every calendar day from January 1, 1990, through early 2024, matching the temporal scope of your research question.\n",
        "  - Number of variables: Typically 5–10 columns in the raw CSV download, including STATION, NAME, DATE, TMAX, TMIN, PRCP, SNOW, and SNWD.\n",
        "  - Description of the variables most relevant to this project:\n",
        "    - DATE: The primary key used to join this data with the EPA AQI and trailhead sensor datasets.\n",
        "    - TMAX: The daily maximum temperature, which serves as a critical control variable to account for how heat affects visitor behavior.\n",
        "    - PRCP: The total daily precipitation, used as a second control variable to isolate the specific impact of air quality from rainy conditions.\n",
        "  - Descriptions of any shortcomings this dataset has with respect to the project:\n",
        "    - Spatial mismatch: The weather station is located at Yosemite Village (elevation ~4,000 ft). Weather patterns (especially temperature and snow) can vary drastically at the higher-elevation trailheads (up to 8,600 ft) where visitor counts are being measured, potentially creating a \"local structure\" mismatch.\n",
        "    - Missing days: Like the EPA monitors, weather sensors occasionally fail or undergo maintenance. These gaps must be handled as genuinely missing data rather than being filled with \"0\" or \"Good\" values, as a missing reading does not imply clear weather.\n",
        "    - Manual entry errors: While NOAA data is generally \"spotless,\" older historical logs may contain idiosyncratic errors or \"table junk\" from manual transcriptions that require diagnostic cleaning using tools like .describe().\n",
        "  - More shortcomings:\n",
        "     - Historical Data Integrity: Although data provided by the National Oceanic and Atmospheric Administration (NOAA) is generally considered reliable, records dating back to 1990 may contain minor inconsistencies due to legacy recording practices or manual transcription processes. To address this, I conducted diagnostic checks using summary statistics (e.g., .describe()) and distributional visualizations (such as histograms) to identify and flag any implausible or out-of-range values that could compromise analytical validity\n",
        "     - Temporal Scope Alignment: While my research question spans 1990–2024, it is necessary to verify that the Yosemite Village station (GHCND:USC00049855) provides consistent and uninterrupted coverage for both TMAX and PRCP throughout this entire period. Any gaps in coverage could create misalignment when merging this dataset with the EPA AQI and trailhead visitor datasets, potentially introducing bias or reducing statistical power.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "1EBJz4QoPHQj",
        "outputId": "955febf2-6755-4872-8266-4ba46efabfb7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'imp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-967286174.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## when their source code .py files are modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-57>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/extensions/autoreload.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msource_from_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m#------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
        "#\n",
        "## this code is necessary for making sure that any modules we load are updated here\n",
        "## when their source code .py files are modified\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3LqiIaSPHQj"
      },
      "outputs": [],
      "source": [
        "# Setup code -- this only needs to be run once after cloning the repo!\n",
        "# this code downloads the data from its source to the `data/00-raw/` directory\n",
        "# if the data hasn't updated you don't need to do this again!\n",
        "\n",
        "# if you don't already have these packages (you should!) uncomment this line\n",
        "# %pip install requests tqdm\n",
        "\n",
        "import sys\n",
        "sys.path.append('./modules') # this tells python where to look for modules to import\n",
        "\n",
        "import get_data # this is where we get the function we need to download data\n",
        "\n",
        "# replace the urls and filenames in this list with your actual datafiles\n",
        "# yes you can use Google drive share links or whatever\n",
        "# format is a list of dictionaries;\n",
        "# each dict has keys of\n",
        "#   'url' where the resource is located\n",
        "#   'filename' for the local filename where it will be stored\n",
        " datafiles = [\n",
        "    { 'url': f'f'https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_{year}.zip,'filename': f'daily_aqi_by_county_{year}.zip'},\n",
        " for year in range(1990, 2024)\n",
        "    { 'url': 'N/A'}\n",
        "]\n",
        "# VY - Data Set 3\n",
        "datafiles = [\n",
        "    {\n",
        "        'url': f'https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_{year}.zip',\n",
        "        'filename': f'daily_aqi_by_county_{year}.zip'\n",
        "    }\n",
        "    for year in range(1990, 2024)\n",
        "]\n",
        "\n",
        "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # This will open a file chooser\n"
      ],
      "metadata": {
        "id": "R5QJEtFFoqtJ",
        "outputId": "efc0df4d-ab89-4f72-b95e-01633b158e60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f99c3a9b-a4a9-43b5-98b5-521c65dcb8cc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f99c3a9b-a4a9-43b5-98b5-521c65dcb8cc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data/00-raw\n",
        "!mv data3weather_raw.csv data/00-raw/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4SA7LYlpF3R",
        "outputId": "772965dd-72b2-4b74-df8b-bcf71d8302f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'data3weather_raw.csv': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSBbjm0mPHQj"
      },
      "source": [
        "### Dataset #1: EPA Daily Air Quality Index — Mariposa County, CA\n",
        "\n",
        "The EPA Daily AQI dataset provides one composite air quality value per day for Mariposa County, California, derived from ground-level monitor readings. The Air Quality Index (AQI) is a unitless scale from 0 to 500. Values 0-50 are \"Good,\" 51-100 are \"Moderate,\" 101-150 are \"Unhealthy for Sensitive Groups,\" 151-200 are \"Unhealthy,\" 201-300 are \"Very Unhealthy,\" and anything above 300 is \"Hazardous.\n",
        "For context, on a Good air quality day hiking in Yosemite poses no health risk. On an Unhealthy day (AQI > 150), even healthy adults may experience respiratory irritation during strenuous outdoor activity, and park rangers may issue warnings. The Defining Parameter column identifies which pollutant drove the AQI value that day, in the Yosemite area this is most commonly PM2.5 (fine particulate matter from wildfire smoke) during summer and fall, or ground-level Ozone during hot weather periods.\n",
        "There are several important concerns with this dataset. First, the data only goes back to 1990, not 1979 as originally proposed, so our analysis will cover 1990-2023. Second, the monitor is located at Yosemite Village and represents a single point within a very large park, air quality at remote trailheads may differ substantially from the recorded value on smoky or windy days. Third, missing days due to monitor downtime are not equivalent to clean-air days and must be treated as genuinely missing rather than filled with \"Good\" values.\n",
        "Finally, because this is a county-level summary, it takes the maximum AQI across all monitors in Mariposa County, which may occasionally reflect conditions outside the park boundary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POsPXn4HPHQj"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load and filter all years to Mariposa County\n",
        "dfs = []\n",
        "for year in range(1990, 2024):\n",
        "    path = f'data/00-raw/daily_aqi_by_county_{year}.zip'\n",
        "    try:\n",
        "        with zipfile.ZipFile(path, 'r') as z:\n",
        "            fname = z.namelist()[0]\n",
        "            with z.open(fname) as f:\n",
        "                df = pd.read_csv(f)\n",
        "                mariposa = df[df['county Name'] == 'Mariposa'].copy()\n",
        "                dfs.append(mariposa)\n",
        "    except Exception as e:\n",
        "        print(f'Could not load {year}: {e}')\n",
        "\n",
        "aqi = pd.concat(dfs, ignore_index=True)\n",
        "aqi['Date'] = pd.to_datetime(aqi['Date'])\n",
        "\n",
        "# 1. Size of dataset\n",
        "print(f'Shape: {aqi.shape}')\n",
        "print(f'Date range: {aqi[\"Date\"].min()} to {aqi[\"Date\"].max()}')\n",
        "\n",
        "# 2. Tidiness check\n",
        "print(f'\\nDuplicate dates: {aqi[\"Date\"].duplicated().sum()}')\n",
        "\n",
        "# 3. Missingness\n",
        "print('\\nMissing values per column:')\n",
        "print(aqi.isnull().sum())\n",
        "\n",
        "# 4. Missing calendar days\n",
        "full_range = pd.date_range(start='1990-01-01', end='2023-12-31')\n",
        "missing_days = full_range.difference(aqi['Date'])\n",
        "print(f'\\nCalendar days with no AQI reading: {len(missing_days)}')\n",
        "print('Missing days are dropped (not filled), because a missing reading')\n",
        "print('does not mean air quality was Good — the monitor was simply offline.')\n",
        "\n",
        "# 5. Outliers\n",
        "print('\\nAQI summary statistics:')\n",
        "print(aqi['AQI'].describe())\n",
        "outliers = aqi[aqi['AQI'] > 300]\n",
        "print(f'\\nDays with AQI > 300 (Hazardous): {len(outliers)}')\n",
        "print(outliers[['Date', 'AQI', 'Category', 'Defining Parameter']])\n",
        "\n",
        "# 6. Defining parameter breakdown\n",
        "print('\\nDefining Parameter frequency:')\n",
        "print(aqi['Defining Parameter'].value_counts())\n",
        "\n",
        "# 7. Save cleaned file\n",
        "os.makedirs('data/02-processed', exist_ok=True)\n",
        "aqi.to_csv('data/02-processed/mariposa_aqi.csv', index=False)\n",
        "print('\\nSaved to data/02-processed/mariposa_aqi.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRfGwprUPHQj"
      },
      "source": [
        "### Dataset #2\n",
        "\n",
        "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these.\n",
        "\n",
        "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
        "\n",
        "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwDLY-FSPHQj"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS3QSKEZPvot"
      },
      "source": [
        "### Dataset #3: Daily Historical Weather Data - Yosemite National Park\n",
        "The National Oceanic and Atmospheric Administration (NOAA) Global Historical Climatology Network (GHCN-Daily) dataset from the Yosemite Village station (GHCND:USC00049855) provides the key meteorological control variables—Daily Maximum Temperature (TMAX) and Total Precipitation (PRCP)—used to isolate the independent effect of air quality on park visitation. Spanning 1990–2023 with approximately 12,418 daily observations, the dataset aligns temporally with the AQI and trailhead visitation records and is merged using the DATE variable as a primary key. TMAX (°F) captures heat-related behavioral responses that may deter visitation, while PRCP (inches) accounts for rain and snowfall that can independently influence trail usage. Although NOAA data is generally reliable, historical records required diagnostic cleaning through summary statistics and distributional checks to identify implausible values and confirm physical plausibility. Additionally, a spatial and elevation mismatch exists between the Yosemite Village station (~4,000 ft) and higher-elevation trailheads (up to 8,600 ft), potentially introducing measurement error. Missing observations—often associated with extreme weather events—were treated as genuinely missing rather than imputed, ensuring that weather controls remain unbiased and analytically defensible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvdP4iCaaXH5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 1. Load the raw weather data\n",
        "path = 'data/00-raw/yosemite_weather_1990_2024.csv'\n",
        "weather = pd.read_csv(path)\n",
        "\n",
        "# 2. Basic Cleaning\n",
        "# Convert Date to datetime for joining\n",
        "weather['DATE'] = pd.to_datetime(weather['DATE'])\n",
        "\n",
        "# 3. Size and Range Check\n",
        "print(f'Shape: {weather.shape}')\n",
        "print(f'Date range: {weather[\"DATE\"].min()} to {weather[\"DATE\"].max()}')\n",
        "\n",
        "# 4. Tidiness Check (One observation per day)\n",
        "# Identifies if the station accidentally recorded multiple entries for one date\n",
        "print(f'\\nDuplicate dates: {weather[\"DATE\"].duplicated().sum()}')\n",
        "\n",
        "# 5. Missingness Audit\n",
        "print('\\nMissing values per critical variable:')\n",
        "# We specifically care about the columns used in our hypothesis\n",
        "print(weather[['TMAX', 'PRCP']].isnull().sum())\n",
        "\n",
        "# 6. Missing Calendar Days (Gap Analysis)\n",
        "# This mimics your Dataset #1 check to see if sensors were offline\n",
        "full_range = pd.date_range(start='1990-01-01', end='2023-12-31')\n",
        "missing_days = full_range.difference(weather['DATE'])\n",
        "print(f'\\nCalendar days with no weather record: {len(missing_days)}')\n",
        "\n",
        "# 7. Outlier Detection (Univariate EDA)\n",
        "print('\\nTemperature (TMAX) Summary Statistics:')\n",
        "print(weather['TMAX'].describe())\n",
        "\n",
        "# Logic check: Yosemite TMAX should realistically be between -10 and 110\n",
        "extreme_temps = weather[(weather['TMAX'] > 115) | (weather['TMAX'] < -30)]\n",
        "print(f'\\nPhysically improbable temperature days found: {len(extreme_temps)}')\n",
        "\n",
        "# 8. Save Processed File\n",
        "os.makedirs('data/02-processed', exist_ok=True)\n",
        "weather.to_csv('data/02-processed/yosemite_weather_clean.csv', index=False)\n",
        "print('\\nSaved to data/02-processed/yosemite_weather_clean.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXQ18BClPHQk"
      },
      "source": [
        "## Ethics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWIg_F8HPHQk"
      },
      "source": [
        "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTLSxMpvPHQk"
      },
      "source": [
        "## Team Expectations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-qXEXcuPHQk"
      },
      "source": [
        "Katelyn Yap's Expectations: Respond to group chat messages within 10 hours. Let members know when they are going to be too busy(midterms etc).\n",
        "\n",
        "Vy Nguyen's Expectations: Communications on Discord will be replied to during school and wake hours 9am-10pm. After school hours it might take awhile. Communication on progress will be updated every week during our meeting (online or in-person).\n",
        "\n",
        "Laird Fowle's Expectations: There will be weekly meetings that discuss deadlines/obligations to ensure everyone is up to date. People will also have a quick response time, the max response wait of 2 hours response, espcially on the day of the deadline\n",
        "\n",
        "Cindy Tao's Expectations: Everyone will complete assigned tasks on time and communicate ahead of the deadline if issues arise. Feedback and disagreements will be handled respectfully and constructively, with the goal of improving the project.\n",
        "\n",
        "Ria Parikh's Expectations: There will be weekly check-ins on assigned tasks and group assignments when almost due. Ensure to respond in a timely matter when texting in the discord chat related to the project. Make sure to address any absences or potential sickness/lateness prior to the due dates to stay on track of deadlines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LNZtX3hPHQk"
      },
      "source": [
        "## Project Timeline Proposal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DF9LsILPHQk"
      },
      "source": [
        "Instructions: Replace this with your timeline.  **PLEASE UPDATE your Timeline!** No battle plan survives contact with the enemy, so make sure we understand how your plans have changed.  Also if you have lost points on the previous checkpoint fix them"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}